import os
import pandas as pd
import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from scipy.sparse import hstack
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

def extract_insight_based_features(text):
    """ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã«åŸºã¥ãæœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ - å›ºå®šé•·25æ¬¡å…ƒ"""
    features = [0.0] * 25  # å›ºå®šé•·ã§åˆæœŸåŒ–
    
    if not text.strip():
        return features
    
    # åŸºæœ¬çµ±è¨ˆ
    words = text.split()
    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
    
    word_count = len(words)
    char_count = len(text)
    sentence_count = len(sentences) if sentences else 1  # 0é™¤ç®—å›é¿
    
    # 1. é•·ã•é–¢é€£ã®ç‰¹å¾´é‡ï¼ˆæœ€ã‚‚é‡è¦ãªå·®åˆ¥åŒ–è¦å› ï¼‰
    features[0] = word_count
    features[1] = char_count
    features[2] = sentence_count
    
    # 2. å¯†åº¦ç‰¹å¾´é‡ï¼ˆAIã¯å†—é•·ãªå‚¾å‘ï¼‰
    features[3] = word_count / sentence_count  # words_per_sentence
    features[4] = char_count / sentence_count  # chars_per_sentence
    
    # 3. å¥èª­ç‚¹ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå·®ãŒæ˜ç¢ºï¼‰
    periods = len(re.findall(r'\.', text))
    commas = len(re.findall(r',', text))
    parentheses = len(re.findall(r'[()]', text))
    quotes = len(re.findall(r'["\']', text))
    
    # æ­£è¦åŒ–ã•ã‚ŒãŸå¥èª­ç‚¹å¯†åº¦
    features[5] = periods / char_count if char_count > 0 else 0
    features[6] = commas / char_count if char_count > 0 else 0
    features[7] = parentheses / char_count if char_count > 0 else 0
    features[8] = quotes / char_count if char_count > 0 else 0
    
    # 4. æ–‡ã”ã¨ã®å¥èª­ç‚¹ä½¿ç”¨ç‡
    features[9] = periods / sentence_count
    features[10] = commas / sentence_count
    features[11] = parentheses / sentence_count
    features[12] = quotes / sentence_count
    
    # 5. èªå½™ã®è¤‡é›‘ã•ï¼ˆAIã®ç‰¹å¾´ã‚’æ‰ãˆã‚‹ï¼‰
    alpha_words = [w for w in words if w.isalpha()]
    if alpha_words:
        features[13] = np.mean([len(w) for w in alpha_words])  # avg_word_length
        unique_words = len(set(w.lower() for w in alpha_words))
        features[14] = unique_words / len(alpha_words)  # lexical_diversity
    else:
        features[13] = 0
        features[14] = 0
    
    # 6. æ–‡ã®é•·ã•ã®å¤‰å‹•æ€§ï¼ˆäººé–“ã®æ–¹ãŒä¸è¦å‰‡ï¼‰
    if len(sentences) > 1:
        sentence_lengths = [len(s.split()) for s in sentences]
        sentence_length_std = np.std(sentence_lengths)
        sentence_length_mean = np.mean(sentence_lengths)
        features[15] = sentence_length_std
        features[16] = sentence_length_std / sentence_length_mean if sentence_length_mean > 0 else 0  # CV
    else:
        features[15] = 0
        features[16] = 0
    
    # 7. ç‰¹æ®Šæ–‡å­—ã®ä½¿ç”¨
    special_chars = len(re.findall(r'[^a-zA-Z0-9\s.,!?;:()\'"/-]', text))
    features[17] = special_chars
    
    # 8. å¤§æ–‡å­—ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
    uppercase_words = len([w for w in words if w.isupper() and len(w) > 1])
    title_case_words = len([w for w in words if w.istitle()])
    features[18] = uppercase_words
    features[19] = title_case_words
    
    # 9. æ•°å­—ã®ä½¿ç”¨
    numbers = len(re.findall(r'\d+', text))
    features[20] = numbers
    
    # 10. ãã®ä»–ã®å¥èª­ç‚¹
    semicolons = len(re.findall(r';', text))
    colons = len(re.findall(r':', text))
    exclamations = len(re.findall(r'!', text))
    questions = len(re.findall(r'\?', text))
    
    features[21] = semicolons
    features[22] = colons
    features[23] = exclamations
    features[24] = questions
    
    # NaN/Infå€¤ã®å‡¦ç†
    for i in range(len(features)):
        if np.isnan(features[i]) or np.isinf(features[i]):
            features[i] = 0.0
    
    return features

def create_comparative_features(file1, file2):
    """æ¯”è¼ƒç‰¹å¾´é‡ã‚’é‡ç‚¹çš„ã«ä½œæˆ"""
    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆå„25æ¬¡å…ƒï¼‰
    features1 = extract_insight_based_features(file1)
    features2 = extract_insight_based_features(file2)
    
    # ãƒ†ã‚­ã‚¹ãƒˆçµåˆ
    combined_text = file1 + " [SEP] " + file2
    
    # é‡è¦ãªæ¯”è¼ƒç‰¹å¾´é‡ï¼ˆ10æ¬¡å…ƒï¼‰
    comparative_features = [0.0] * 10
    
    # 1. é•·ã•ã®æ¯”è¼ƒï¼ˆæœ€é‡è¦ï¼‰
    len1, len2 = len(file1.split()), len(file2.split())
    char1, char2 = len(file1), len(file2)
    sent1 = len([s for s in re.split(r'[.!?]+', file1) if s.strip()])
    sent2 = len([s for s in re.split(r'[.!?]+', file2) if s.strip()])
    
    comparative_features[0] = len1 / max(1, len2)  # word ratio
    comparative_features[1] = char1 / max(1, char2)  # char ratio
    comparative_features[2] = sent1 / max(1, sent2)  # sentence ratio
    
    # 2. å¥èª­ç‚¹ä½¿ç”¨ã®æ¯”è¼ƒ
    punct1 = len(re.findall(r'[.!?,:;()]', file1))
    punct2 = len(re.findall(r'[.!?,:;()]', file2))
    comparative_features[3] = punct1 / max(1, punct2)
    
    # 3. èªå½™å¤šæ§˜æ€§ã®æ¯”è¼ƒ
    words1 = [w.lower() for w in file1.split() if w.isalpha()]
    words2 = [w.lower() for w in file2.split() if w.isalpha()]
    
    if words1 and words2:
        diversity1 = len(set(words1)) / len(words1)
        diversity2 = len(set(words2)) / len(words2)
        comparative_features[4] = diversity1 / max(0.001, diversity2)
    else:
        comparative_features[4] = 1.0
    
    # 4. é‡è¦ãªå·®åˆ†ç‰¹å¾´é‡ï¼ˆ5æ¬¡å…ƒï¼‰
    important_indices = [0, 1, 2, 3, 4]  # word_count, char_count, sentence_count, words_per_sentence, chars_per_sentence
    for i, idx in enumerate(important_indices):
        comparative_features[5 + i] = features1[idx] - features2[idx]
    
    # å·®åˆ†ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰
    diff_features = [f1 - f2 for f1, f2 in zip(features1, features2)]
    
    # æ¯”ç‡ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰
    ratio_features = []
    for f1, f2 in zip(features1, features2):
        if f2 != 0:
            ratio = f1 / f2
        else:
            ratio = 1.0 if f1 == 0 else 2.0
        
        # ç•°å¸¸å€¤ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        ratio = max(-10, min(10, ratio))
        ratio_features.append(ratio)
    
    # å…¨ç‰¹å¾´é‡ã‚’çµåˆ (25 + 25 + 10 + 25 + 25 = 110æ¬¡å…ƒ)
    all_features = features1 + features2 + comparative_features + diff_features + ratio_features
    
    # æœ€çµ‚çš„ãªç•°å¸¸å€¤å‡¦ç†
    for i in range(len(all_features)):
        if np.isnan(all_features[i]) or np.isinf(all_features[i]):
            all_features[i] = 0.0
        else:
            all_features[i] = max(-100, min(100, all_features[i]))
    
    return combined_text, all_features

def read_text_pair(folder, article_index):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ã‚’èª­ã¿è¾¼ã¿"""
    folder_name = f"article_{int(article_index):04d}"
    base_path = os.path.join(folder, folder_name)
    with open(os.path.join(base_path, "file_1.txt"), encoding="utf-8") as f:
        file1 = f.read()
    with open(os.path.join(base_path, "file_2.txt"), encoding="utf-8") as f:
        file2 = f.read()
    return file1, file2

def prepare_insight_training_data(train_df):
    """åˆ†æçµæœã«åŸºã¥ãè¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
    X_text = []
    X_features = []
    y = []

    print("åˆ†æçµæœã«åŸºã¥ãç‰¹å¾´é‡ã‚’æŠ½å‡ºä¸­...")
    for idx, row in train_df.iterrows():
        try:
            file1, file2 = read_text_pair("train", row["id"])

            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: file1 vs file2
            combined_text1, features1 = create_comparative_features(file1, file2)
            X_text.append(combined_text1)
            X_features.append(features1)
            y.append(1 if row["real_text_id"] == 1 else 0)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: file2 vs file1
            combined_text2, features2 = create_comparative_features(file2, file1)
            X_text.append(combined_text2)
            X_features.append(features2)
            y.append(1 if row["real_text_id"] == 2 else 0)
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ï¼ˆID: {row['id']}ï¼‰: {e}")
            continue

    print(f"ğŸ“Š ç‰¹å¾´é‡æ¬¡å…ƒæ•°: {len(X_features[0]) if X_features else 'æœªå®šç¾©'}")
    print(f"ğŸ“Š å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_text)}")
    
    # ç‰¹å¾´é‡ã®æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
    if X_features:
        feature_lengths = [len(f) for f in X_features]
        print(f"ğŸ“Š ç‰¹å¾´é‡é•·ã®ç¯„å›²: {min(feature_lengths)} - {max(feature_lengths)}")
        if min(feature_lengths) != max(feature_lengths):
            print("âš ï¸ ç‰¹å¾´é‡ã®æ¬¡å…ƒãŒä¸ä¸€è‡´ã§ã™ã€‚ä¿®æ­£ä¸­...")
            # æœ€çŸ­ã®é•·ã•ã«åˆã‚ã›ã‚‹
            min_len = min(feature_lengths)
            X_features = [f[:min_len] for f in X_features]
            print(f"âœ… ç‰¹å¾´é‡ã‚’{min_len}æ¬¡å…ƒã«çµ±ä¸€ã—ã¾ã—ãŸ")
    
    return X_text, X_features, y

def create_optimized_tfidf(X_text):
    """æœ€é©åŒ–ã•ã‚ŒãŸTF-IDF"""
    vectorizer = TfidfVectorizer(
        max_features=2000,
        min_df=2,
        max_df=0.85,
        ngram_range=(1, 2),
        stop_words='english',
        sublinear_tf=True,
        norm='l2'
    )
    
    X_tfidf = vectorizer.fit_transform(X_text)
    print(f"ğŸ“Š TF-IDFç‰¹å¾´é‡: {X_tfidf.shape}")
    return vectorizer, X_tfidf

def train_insight_model(X_combined, y):
    """åˆ†æçµæœã«åŸºã¥ããƒ¢ãƒ‡ãƒ«è¨“ç·´"""
    print("=== æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===")
    
    models = {
        'GradientBoosting': GradientBoostingClassifier(
            n_estimators=150,
            max_depth=8,
            learning_rate=0.1,
            subsample=0.8,
            random_state=42
        ),
        'RandomForest': RandomForestClassifier(
            n_estimators=200,
            max_depth=12,
            min_samples_split=4,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        ),
        'LogisticRegression': LogisticRegression(
            C=0.5,
            penalty='l2',
            solver='liblinear',
            random_state=42,
            max_iter=5000
        )
    }
    
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    best_score = 0
    best_model = None
    best_name = ""
    
    for name, model in models.items():
        try:
            scores = cross_val_score(model, X_combined, y, cv=cv, scoring='accuracy')
            mean_score = scores.mean()
            print(f"{name}: {mean_score:.4f} (+/- {scores.std() * 2:.4f})")
            
            if mean_score > best_score:
                best_score = mean_score
                best_model = model
                best_name = name
        except Exception as e:
            print(f"{name}ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"\næœ€é©ãƒ¢ãƒ‡ãƒ«: {best_name} (CV Score: {best_score:.4f})")
    
    # æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    best_model.fit(X_combined, y)
    
    return best_model, best_name

def predict_insight_test(test_dir, vectorizer, scaler, model):
    """ãƒ†ã‚¹ãƒˆäºˆæ¸¬"""
    print("=== ãƒ†ã‚¹ãƒˆäºˆæ¸¬å®Ÿè¡Œ ===")
    
    if not os.path.exists(test_dir):
        print(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{test_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []
    
    test_folders = sorted([f for f in os.listdir(test_dir) if f.startswith("article_")])
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ•ã‚©ãƒ«ãƒ€æ•°: {len(test_folders)}")
    
    results = []
    confidence_scores = []
    
    for folder in test_folders:
        try:
            article_id = folder.split("_")[1]
            file1, file2 = read_text_pair(test_dir, article_id)
            
            # ä¸¡æ–¹å‘ã§äºˆæ¸¬
            prob1 = predict_insight_pair(file1, file2, vectorizer, scaler, model)
            prob2 = predict_insight_pair(file2, file1, vectorizer, scaler, model)
            
            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
            confidence1 = abs(prob1 - 0.5)
            confidence2 = abs(prob2 - 0.5)
            
            # ã‚ˆã‚Šä¿¡é ¼åº¦ã®é«˜ã„äºˆæ¸¬ã‚’æ¡ç”¨
            if confidence1 > confidence2:
                real = 1 if prob1 > 0.5 else 2
                confidence = confidence1
            else:
                real = 1 if prob1 > prob2 else 2
                confidence = max(confidence1, confidence2)
            
            results.append((int(article_id), real))
            confidence_scores.append(confidence)
            
        except Exception as e:
            print(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼ï¼ˆ{folder}ï¼‰: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬
            article_id = folder.split("_")[1]
            results.append((int(article_id), 1))
            confidence_scores.append(0.0)
    
    # ä¿¡é ¼åº¦çµ±è¨ˆ
    if confidence_scores:
        print(f"äºˆæ¸¬ä¿¡é ¼åº¦ - å¹³å‡: {np.mean(confidence_scores):.3f}, æœ€å°: {np.min(confidence_scores):.3f}, æœ€å¤§: {np.max(confidence_scores):.3f}")
    
    return results

def predict_insight_pair(text1, text2, vectorizer, scaler, model):
    """å˜ä¸€ãƒšã‚¢äºˆæ¸¬"""
    try:
        combined_text, features = create_comparative_features(text1, text2)
        
        # TF-IDF
        tfidf = vectorizer.transform([combined_text])
        
        # çµ±è¨ˆç‰¹å¾´é‡
        features_scaled = scaler.transform(np.array([features]))
        
        # çµåˆ
        X_test = hstack([tfidf, features_scaled])
        
        return model.predict_proba(X_test)[0][1]
    except Exception as e:
        print(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã«åŸºã¥ãæœ€é©åŒ–åˆ†é¡å™¨ï¼ˆä¿®æ­£ç‰ˆï¼‰ ===\n")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    train_df = pd.read_csv("train.csv")
    print(f"ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
    
    # ç‰¹å¾´é‡ä½œæˆ
    X_text, X_features, y = prepare_insight_training_data(train_df)
    
    if not X_features:
        print("âŒ ç‰¹å¾´é‡ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # TF-IDFç‰¹å¾´é‡
    vectorizer, X_tfidf = create_optimized_tfidf(X_text)
    
    # çµ±è¨ˆç‰¹å¾´é‡ã®æ­£è¦åŒ–
    print("çµ±è¨ˆç‰¹å¾´é‡ã®æ­£è¦åŒ–ä¸­...")
    scaler = StandardScaler()
    
    # numpyé…åˆ—ã«å¤‰æ›ï¼ˆäº‹å‰ãƒã‚§ãƒƒã‚¯ï¼‰
    X_features_array = np.array(X_features, dtype=float)
    print(f"ğŸ“Š çµ±è¨ˆç‰¹å¾´é‡ã®å½¢çŠ¶: {X_features_array.shape}")
    
    X_features_scaled = scaler.fit_transform(X_features_array)
    
    # ç‰¹å¾´é‡çµåˆ
    X_combined = hstack([X_tfidf, X_features_scaled])
    print(f"ğŸ“Š æœ€çµ‚ç‰¹å¾´é‡è¡Œåˆ—: {X_combined.shape}")
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    model, model_name = train_insight_model(X_combined, y)
    
    # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
    results = predict_insight_test("test", vectorizer, scaler, model)
    
    if results:
        # çµæœä¿å­˜
        submission_df = pd.DataFrame(results, columns=["id", "real_text_id"])
        submission_df.to_csv("submission_insight_based_fixed.csv", index=False)
        
        print(f"\n=== åˆ†æçµæœã«åŸºã¥ãæœ€é©åŒ–å®Œäº† ===")
        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        print(f"äºˆæ¸¬åˆ†å¸ƒ: {submission_df['real_text_id'].value_counts().to_dict()}")
        print("âœ… submission_insight_based_fixed.csv ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    else:
        print("âŒ äºˆæ¸¬çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    main()